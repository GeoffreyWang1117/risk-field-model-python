"""
highDæ•°æ®é›†å¤„ç†æ¨¡å—
HighD Dataset Processing Module for Risk Field Model

è¿™ä¸ªæ¨¡å—å¤„ç†highDæ•°æ®é›†çš„åŠ è½½ã€é¢„å¤„ç†å’Œæ ¼å¼è½¬æ¢
This module handles loading, preprocessing and format conversion of highD dataset
"""

import os
import sys
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class HighDProcessor:
    """
    highDæ•°æ®é›†å¤„ç†å™¨
    ä¸“é—¨ç”¨äºå¤„ç†å¾·å›½é«˜é€Ÿå…¬è·¯çœŸå®è½¨è¿¹æ•°æ®
    """
    
    def __init__(self, data_root: str = None):
        """
        åˆå§‹åŒ–highDæ•°æ®å¤„ç†å™¨
        
        Parameters:
        data_root: highDæ•°æ®é›†æ ¹ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸º ../HighDdata/
        """
        if data_root is None:
            # é»˜è®¤æ•°æ®é›†è·¯å¾„ï¼ˆä¸ä»£ç ç›®å½•å¹³è¡Œï¼‰
            current_dir = Path(__file__).parent
            self.data_root = current_dir.parent / "HighDdata"
        else:
            self.data_root = Path(data_root)
            
        self.recordings_meta = {}
        self.current_recording = None
        
        # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
        self._check_data_availability()
        
    def _check_data_availability(self):
        """æ£€æŸ¥highDæ•°æ®é›†æ˜¯å¦å¯ç”¨"""
        print(f"ğŸ” æ£€æŸ¥highDæ•°æ®é›†è·¯å¾„: {self.data_root}")
        
        if not self.data_root.exists():
            print("âš ï¸  highDæ•°æ®é›†æœªæ‰¾åˆ°ï¼")
            print("è¯·ç¡®ä¿HighDdataæ–‡ä»¶å¤¹ä¸ä»£ç ç›®å½•å¹³è¡Œæ”¾ç½®")
            print(f"é¢„æœŸè·¯å¾„: {self.data_root}")
            self.data_available = False
            return
            
        # æŸ¥æ‰¾CSVæ–‡ä»¶
        csv_files = list(self.data_root.glob("*.csv"))
        if len(csv_files) == 0:
            print("âš ï¸  æœªæ‰¾åˆ°highD CSVæ•°æ®æ–‡ä»¶")
            self.data_available = False
            return
            
        print(f"âœ… æ‰¾åˆ° {len(csv_files)} ä¸ªhighDæ•°æ®æ–‡ä»¶")
        self.data_available = True
        
        # è¯†åˆ«å½•åˆ¶ID
        self._identify_recordings()
    
    def _identify_recordings(self):
        """è¯†åˆ«å¯ç”¨çš„å½•åˆ¶æ–‡ä»¶"""
        print("ğŸ“‹ è¯†åˆ«highDå½•åˆ¶æ–‡ä»¶...")
        
        # æŸ¥æ‰¾è½¨è¿¹æ–‡ä»¶ï¼ˆé€šå¸¸å‘½åä¸ºXX_tracks.csvï¼‰
        tracks_files = list(self.data_root.glob("*_tracks.csv"))
        meta_files = list(self.data_root.glob("*_tracksMeta.csv"))
        
        for tracks_file in tracks_files:
            # æå–å½•åˆ¶ID (ä¾‹å¦‚: "01_tracks.csv" -> "01")
            recording_id = tracks_file.stem.replace("_tracks", "")
            
            # æŸ¥æ‰¾å¯¹åº”çš„metaæ–‡ä»¶
            meta_file = self.data_root / f"{recording_id}_tracksMeta.csv"
            
            if meta_file.exists():
                self.recordings_meta[recording_id] = {
                    'tracks_file': tracks_file,
                    'meta_file': meta_file,
                    'recording_id': recording_id
                }
                print(f"   âœ… å½•åˆ¶ {recording_id}: {tracks_file.name}")
            else:
                print(f"   âš ï¸  å½•åˆ¶ {recording_id}: ç¼ºå°‘metaæ–‡ä»¶")
        
        print(f"ğŸ“Š æ€»è®¡å¯ç”¨å½•åˆ¶: {len(self.recordings_meta)} ä¸ª")
    
    def list_available_recordings(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å½•åˆ¶ID"""
        if not self.data_available:
            print("âŒ æ•°æ®é›†ä¸å¯ç”¨")
            return []
        
        return list(self.recordings_meta.keys())
    
    def load_recording(self, recording_id: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        åŠ è½½æŒ‡å®šå½•åˆ¶çš„æ•°æ®
        
        Parameters:
        recording_id: å½•åˆ¶ID (ä¾‹å¦‚ "01", "02", ...)
        
        Returns:
        tuple: (tracks_df, meta_df) è½¨è¿¹æ•°æ®å’Œå…ƒæ•°æ®
        """
        if not self.data_available:
            raise ValueError("highDæ•°æ®é›†ä¸å¯ç”¨")
        
        if recording_id not in self.recordings_meta:
            available = list(self.recordings_meta.keys())
            raise ValueError(f"å½•åˆ¶ID {recording_id} ä¸å­˜åœ¨ã€‚å¯ç”¨å½•åˆ¶: {available}")
        
        print(f"ğŸ“‚ åŠ è½½å½•åˆ¶ {recording_id}...")
        
        recording_info = self.recordings_meta[recording_id]
        
        # åŠ è½½è½¨è¿¹æ•°æ®
        print("   è¯»å–è½¨è¿¹æ•°æ®...")
        tracks_df = pd.read_csv(recording_info['tracks_file'])
        
        # åŠ è½½å…ƒæ•°æ®
        print("   è¯»å–å…ƒæ•°æ®...")  
        meta_df = pd.read_csv(recording_info['meta_file'])
        
        self.current_recording = recording_id
        
        print(f"âœ… æˆåŠŸåŠ è½½å½•åˆ¶ {recording_id}")
        print(f"   è½¨è¿¹æ•°æ®: {len(tracks_df)} è¡Œ")
        print(f"   å…ƒæ•°æ®: {len(meta_df)} æ¡è½¨è¿¹")
        
        return tracks_df, meta_df
    
    def get_recording_summary(self, recording_id: str) -> Dict:
        """
        è·å–å½•åˆ¶çš„åŸºæœ¬ä¿¡æ¯æ‘˜è¦
        """
        tracks_df, meta_df = self.load_recording(recording_id)
        
        summary = {
            'recording_id': recording_id,
            'total_frames': tracks_df['frame'].max() - tracks_df['frame'].min() + 1,
            'total_vehicles': len(meta_df),
            'duration_seconds': (tracks_df['frame'].max() - tracks_df['frame'].min()) * 0.04,  # 25Hz
            'frame_rate': 25.0,
            'driving_direction': meta_df['drivingDirection'].value_counts().to_dict(),
            'vehicle_classes': meta_df['class'].value_counts().to_dict()
        }
        
        return summary
    
    def extract_scenario_by_time(self, tracks_df: pd.DataFrame, meta_df: pd.DataFrame, 
                                start_frame: int, duration_frames: int = 125) -> List[Dict]:
        """
        æå–æŒ‡å®šæ—¶é—´æ®µçš„åœºæ™¯æ•°æ®
        
        Parameters:
        start_frame: å¼€å§‹å¸§
        duration_frames: æŒç»­å¸§æ•° (é»˜è®¤125å¸§ = 5ç§’ @ 25Hz)
        
        Returns:
        List[Dict]: è½¦è¾†æ•°æ®åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{'id': 1, 'x': 10.5, 'y': 2.1, 'speed': 60}, ...]
        """
        end_frame = start_frame + duration_frames
        
        # æå–æŒ‡å®šæ—¶é—´æ®µçš„è½¨è¿¹æ•°æ®
        scenario_tracks = tracks_df[
            (tracks_df['frame'] >= start_frame) & 
            (tracks_df['frame'] < end_frame)
        ].copy()
        
        if len(scenario_tracks) == 0:
            return []
        
        # é€‰æ‹©ä¸­é—´å¸§ä½œä¸ºå¿«ç…§
        snapshot_frame = start_frame + duration_frames // 2
        snapshot_data = scenario_tracks[scenario_tracks['frame'] == snapshot_frame]
        
        vehicles = []
        for _, vehicle in snapshot_data.iterrows():
            # è®¡ç®—é€Ÿåº¦ (m/s è½¬æ¢ä¸º km/h)
            speed_ms = np.sqrt(vehicle['xVelocity']**2 + vehicle['yVelocity']**2)
            speed_kmh = speed_ms * 3.6
            
            vehicle_data = {
                'id': int(vehicle['id']),
                'x': float(vehicle['x']),
                'y': float(vehicle['y']),
                'speed': float(speed_kmh)
            }
            vehicles.append(vehicle_data)
        
        return vehicles
    
    def find_overtaking_scenarios(self, tracks_df: pd.DataFrame, meta_df: pd.DataFrame, 
                                 min_speed_diff: float = 10.0) -> List[Dict]:
        """
        è‡ªåŠ¨è¯†åˆ«è¶…è½¦åœºæ™¯
        
        Parameters:
        min_speed_diff: æœ€å°é€Ÿåº¦å·®å¼‚ (km/h)
        
        Returns:
        List[Dict]: è¶…è½¦åœºæ™¯åˆ—è¡¨
        """
        print("ğŸ” æœç´¢è¶…è½¦åœºæ™¯...")
        
        overtaking_scenarios = []
        
        # æŒ‰å¸§åˆ†ç»„å¤„ç†
        frames = sorted(tracks_df['frame'].unique())
        
        for i, frame in enumerate(frames[::50]):  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
            frame_data = tracks_df[tracks_df['frame'] == frame]
            
            # æŸ¥æ‰¾ç›¸é‚»è½¦é“çš„è½¦è¾†å¯¹
            for _, vehicle1 in frame_data.iterrows():
                for _, vehicle2 in frame_data.iterrows():
                    if vehicle1['id'] >= vehicle2['id']:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨ç›¸é‚»è½¦é“
                    y_diff = abs(vehicle1['y'] - vehicle2['y'])
                    if not (2.0 < y_diff < 5.0):  # è½¦é“å®½åº¦çº¦3.5m
                        continue
                    
                    # æ£€æŸ¥é€Ÿåº¦å·®å¼‚
                    speed1 = np.sqrt(vehicle1['xVelocity']**2 + vehicle1['yVelocity']**2) * 3.6
                    speed2 = np.sqrt(vehicle2['xVelocity']**2 + vehicle2['yVelocity']**2) * 3.6
                    
                    if abs(speed1 - speed2) > min_speed_diff:
                        vehicles = self.extract_scenario_by_time(tracks_df, meta_df, frame, 125)
                        
                        if len(vehicles) >= 3:  # è‡³å°‘3è¾†è½¦çš„åœºæ™¯
                            scenario = {
                                'type': 'overtaking',
                                'frame': frame,
                                'vehicles': vehicles,
                                'description': f'è¶…è½¦åœºæ™¯ - å¸§{frame}'
                            }
                            overtaking_scenarios.append(scenario)
                            
                            if len(overtaking_scenarios) >= 5:  # é™åˆ¶æ•°é‡
                                break
                
                if len(overtaking_scenarios) >= 5:
                    break
            
            if len(overtaking_scenarios) >= 5:
                break
        
        print(f"âœ… æ‰¾åˆ° {len(overtaking_scenarios)} ä¸ªè¶…è½¦åœºæ™¯")
        return overtaking_scenarios
    
    def convert_to_risk_field_format(self, vehicles: List[Dict]) -> List[List]:
        """
        è½¬æ¢ä¸ºé£é™©åœºæ¨¡å‹æ‰€éœ€çš„æ ¼å¼
        
        Parameters:
        vehicles: highDæ ¼å¼çš„è½¦è¾†æ•°æ®
        
        Returns:
        List[List]: é£é™©åœºæ¨¡å‹æ ¼å¼ [[id, x, y, speed], ...]
        """
        risk_field_vehicles = []
        
        for vehicle in vehicles:
            risk_field_vehicle = [
                vehicle['id'],
                vehicle['x'],
                vehicle['y'],  
                vehicle['speed']
            ]
            risk_field_vehicles.append(risk_field_vehicle)
        
        return risk_field_vehicles
    
    def save_scenarios(self, scenarios: List[Dict], output_file: str):
        """
        ä¿å­˜æå–çš„åœºæ™¯æ•°æ®
        
        Parameters:
        scenarios: åœºæ™¯æ•°æ®åˆ—è¡¨
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œç¡®ä¿JSONå¯åºåˆ—åŒ–
        serializable_scenarios = []
        for scenario in scenarios:
            serializable_scenario = {
                'type': scenario['type'],
                'frame': int(scenario['frame']),
                'description': scenario['description'],
                'vehicles': []
            }
            
            for vehicle in scenario['vehicles']:
                serializable_vehicle = {
                    'id': int(vehicle['id']),
                    'x': float(vehicle['x']),
                    'y': float(vehicle['y']),
                    'speed': float(vehicle['speed'])
                }
                serializable_scenario['vehicles'].append(serializable_vehicle)
            
            serializable_scenarios.append(serializable_scenario)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_scenarios, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ åœºæ™¯æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
    
    def create_data_usage_guide(self):
        """åˆ›å»ºæ•°æ®ä½¿ç”¨æŒ‡å—"""
        guide = """
# highDæ•°æ®é›†ä½¿ç”¨æŒ‡å—

## æ•°æ®é›†ç»“æ„
```
HighDdata/                    # ä¸ä»£ç ç›®å½•å¹³è¡Œ
â”œâ”€â”€ 01_tracks.csv            # å½•åˆ¶01è½¨è¿¹æ•°æ®
â”œâ”€â”€ 01_tracksMeta.csv        # å½•åˆ¶01å…ƒæ•°æ®
â”œâ”€â”€ 02_tracks.csv            # å½•åˆ¶02è½¨è¿¹æ•°æ®  
â”œâ”€â”€ 02_tracksMeta.csv        # å½•åˆ¶02å…ƒæ•°æ®
â””â”€â”€ ...                      # æ›´å¤šå½•åˆ¶æ–‡ä»¶
```

## åŸºæœ¬ä½¿ç”¨

```python
from highd_processor import HighDProcessor

# åˆå§‹åŒ–å¤„ç†å™¨
processor = HighDProcessor()

# åˆ—å‡ºå¯ç”¨å½•åˆ¶
recordings = processor.list_available_recordings()
print(f"å¯ç”¨å½•åˆ¶: {recordings}")

# åŠ è½½æ•°æ®
tracks_df, meta_df = processor.load_recording("01")

# æå–åœºæ™¯
vehicles = processor.extract_scenario_by_time(tracks_df, meta_df, start_frame=1000)

# è½¬æ¢æ ¼å¼ç”¨äºé£é™©åœºè®¡ç®—
risk_field_vehicles = processor.convert_to_risk_field_format(vehicles)

# ä½¿ç”¨é£é™©åœºæ¨¡å‹
from risk_field_model import RiskFieldModel
model = RiskFieldModel()
F_total, *_ = model.calculate_scene_risk_field(risk_field_vehicles)
```

## æ³¨æ„äº‹é¡¹

1. **æ•°æ®ç‰ˆæƒ**: highDæ•°æ®é›†å—ç‰ˆæƒä¿æŠ¤ï¼Œä»…ç”¨äºå­¦æœ¯ç ”ç©¶
2. **æ•°æ®å¤§å°**: æ•°æ®é›†æ–‡ä»¶è¾ƒå¤§ï¼Œä¸åº”ä¸Šä¼ åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
3. **å¤„ç†é€Ÿåº¦**: å¤§æ•°æ®é›†å¤„ç†éœ€è¦æ—¶é—´ï¼Œå»ºè®®ä»å°æ ·æœ¬å¼€å§‹
4. **å†…å­˜ä½¿ç”¨**: åŠ è½½å®Œæ•´å½•åˆ¶å¯èƒ½å ç”¨å¤§é‡å†…å­˜

## å¸¸è§é—®é¢˜

Q: æ•°æ®é›†è·¯å¾„æ‰¾ä¸åˆ°ï¼Ÿ
A: ç¡®ä¿HighDdataæ–‡ä»¶å¤¹ä¸python_reproductionæ–‡ä»¶å¤¹å¹³è¡Œæ”¾ç½®

Q: CSVæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Ÿ
A: ç¡®ä¿ä¸‹è½½çš„æ˜¯å®˜æ–¹highDæ•°æ®é›†çš„CSVæ ¼å¼ç‰ˆæœ¬

Q: å†…å­˜ä¸è¶³ï¼Ÿ
A: å¯ä»¥åˆ†æ‰¹å¤„ç†æ•°æ®ï¼Œæˆ–ä½¿ç”¨è¾ƒå°çš„æ—¶é—´çª—å£
"""
        
        with open("highd_usage_guide.md", "w", encoding="utf-8") as f:
            f.write(guide)
        
        print("ğŸ“– å·²åˆ›å»ºæ•°æ®ä½¿ç”¨æŒ‡å—: highd_usage_guide.md")


def demo_highd_processing():
    """
    æ¼”ç¤ºhighDæ•°æ®å¤„ç†åŠŸèƒ½
    """
    print("ğŸš— highDæ•°æ®é›†å¤„ç†æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = HighDProcessor()
    
    if not processor.data_available:
        print("âš ï¸  æ¼”ç¤ºéœ€è¦highDæ•°æ®é›†")
        print("è¯·å°†HighDdataæ–‡ä»¶å¤¹æ”¾ç½®åœ¨ä»£ç ç›®å½•çš„çˆ¶çº§ç›®å½•ä¸­")
        return None
    
    # åˆ—å‡ºå¯ç”¨å½•åˆ¶
    recordings = processor.list_available_recordings()
    print(f"\nğŸ“‹ å¯ç”¨å½•åˆ¶: {recordings}")
    
    if len(recordings) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„å½•åˆ¶æ–‡ä»¶")
        return None
    
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªå½•åˆ¶è¿›è¡Œæ¼”ç¤º
    demo_recording = recordings[0]
    print(f"\nğŸ¯ ä½¿ç”¨å½•åˆ¶ {demo_recording} è¿›è¡Œæ¼”ç¤º")
    
    try:
        # è·å–å½•åˆ¶æ‘˜è¦
        summary = processor.get_recording_summary(demo_recording)
        print("\nğŸ“Š å½•åˆ¶æ‘˜è¦:")
        print(f"   å½•åˆ¶ID: {summary['recording_id']}")
        print(f"   æ€»å¸§æ•°: {summary['total_frames']}")
        print(f"   æ€»è½¦è¾†æ•°: {summary['total_vehicles']}")
        print(f"   æŒç»­æ—¶é—´: {summary['duration_seconds']:.1f} ç§’")
        print(f"   è¡Œé©¶æ–¹å‘: {summary['driving_direction']}")
        
        # åŠ è½½æ•°æ®
        tracks_df, meta_df = processor.load_recording(demo_recording)
        
        # æå–ä¸€ä¸ªæ—¶é—´æ®µçš„åœºæ™¯
        print(f"\nğŸ¬ æå–åœºæ™¯å¿«ç…§...")
        vehicles = processor.extract_scenario_by_time(tracks_df, meta_df, start_frame=1000, duration_frames=125)
        
        if len(vehicles) > 0:
            print(f"   âœ… æå–åˆ° {len(vehicles)} è¾†è½¦çš„åœºæ™¯")
            
            # æ˜¾ç¤ºå‰å‡ è¾†è½¦çš„ä¿¡æ¯
            for i, vehicle in enumerate(vehicles[:3]):
                print(f"     è½¦è¾†{vehicle['id']}: x={vehicle['x']:.1f}m, y={vehicle['y']:.1f}m, é€Ÿåº¦={vehicle['speed']:.1f}km/h")
            
            # è½¬æ¢ä¸ºé£é™©åœºæ ¼å¼
            risk_field_vehicles = processor.convert_to_risk_field_format(vehicles)
            print(f"\nğŸ”„ å·²è½¬æ¢ä¸ºé£é™©åœºæ ¼å¼")
            
            return processor, risk_field_vehicles
        else:
            print("   âš ï¸  è¯¥æ—¶é—´æ®µæ²¡æœ‰è½¦è¾†æ•°æ®")
    
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return None
    
    return processor


if __name__ == "__main__":
    processor = demo_highd_processing()
